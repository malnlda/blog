使用 LLM 的目标

目前阶段 LLM 模型和工具竞争异常激烈，弃用 deepseek-r1、投奔 gpt-o1 才没多久，就体验到 grok 3 的 deep search 检索结果快速且精确，claude sonnet 3.7 可以用「一杯瑞幸的钱」做出极高完成度且非常漂亮的网页和应用，gpt-4.5 具备更强大的世界知识、准确度和拟人度大幅提升，gemini 2.0 flash (image generation) 可以一句话修图、一句话生成数十张图片的分镜动作，gemini 2.0 也推出了 deep research，眼花缭乱，更不提 manus 等 agent 工具层出不穷搅动市场，以及明天（据传）就要发布 deepseep-r2 等等，极易激起用户对 ai 工具的 fomo 焦虑。在我看来，紧密关注 LLM 模型和工具的发展是必须的，但也不必频繁切换转投「阵营」。工具毕竟只是工具，应当关注自己的使用场景，明确使用目标，按需选择工具，例如：

1.LLM 作为快速研究工具

我们以前如果需要速读一本书，需要快速进入一个知识领域，需要快速了解一个主题下的整体分析，比较通用的办法是到豆瓣翻一篇书评、到知乎或公众号找一篇长文解析，找得到最好，找不到就得自己从头学起。而自从模型发展出 deep research 能力，以及类 deep research 的 agent 工具涌现，在满足「快速研究」目的上，很大范围内已经不需要依赖文章检索。例如，你可以向模型询问：「如果我想要通过 deep research / 学习理解《古代法》这本书的整体内容 / 研究全世界范围内律师使用 LLM 的发展情况 / 研究人身商业保险在家庭财富传承和婚姻家事纠纷领域的相关问题，我应该如何撰写提示词？」对模型生成的提示词结果，按需要做一些调整，比如「请你检索英语世界内容，并用中文输出 / 请你输出不少于两万中文字的结果」等，然后将整理好的提示词输入到 deep research 或类 deep search 的 agent 工具中，等待生成结果。测试发现，这一结果的质量，足以实现「快速研究」的目标，能够从中提取学习和写作灵感，甚至稍作修改即可输出成专业文章。

2.LLM 作为知识库工具

通用模型的知识过于宽泛，无法满足自己本专业获取知识和团队协作的需求，因而需要搭建知识库，实现对既有知识内容的快速检索、总结、分析……这已成为全网关于 LLM 讨论最多的话题，是最急切的需求，是大部分用户 fomo 焦虑最严重的话题。我们法律实务领域在此话题下的 fomo 焦虑度更为甚之，律师日常工作需要解答客户法律咨询，但对于每个问题都不敢随意回答，进而需要做大量的法律研究、案例检索，消耗大量时间。但同行们发现通用模型的答案并不靠谱，会产生编造法条、案例的「幻觉」，故此更为急切地需要能够解决法律知识库的模型工具。于是，新橙推出了 alphagpt，定价 5000 元/三年；熊猫推出 deepseek 大模型一体机，价格不详；智合推出「deepseek 法律一体机，价格 50 万……

在我看来，对于任何一件互联网上炒作特别热门的事，都需要打开自己脑子里的「防骗警报器」，审视自己是否有必要打开付款码淌入这片浑水。通用模型难以用于做垂直领域知识库，主要源于两个原因：

第一，上下文长度限制。在单一对话中，为了「记住」前边说过的话，每向发一次对话要求，模型都会将之前的内容全部阅读一遍，如此就会消耗 tokens。对话内容越多，模型每次消耗的 tokens 就越大。由于每个模型支持的上下文 tokens 有限，如果对话整体内容超出限制，模型就会「忘记」之前内容，导致答复不精确。目前 deepseek-r1 上下文长度限制为 128k（api 为 64k），约对应 64k 中文字（api 为 32k），gpt-4o 为 128k，gemini-2.0-pro 为 200k。原理上模型需要对输入的内容做「向量化」解析，通俗理解（我也只懂通俗理解）是将自然语言转化为模型可识别的向量文本。而即便 64k 中文字看起来已经很多，但不同模型解析文本的能力有差异，或是选择只读每段首句，或是选择只读重点部分，一般也不会全文阅读，从而使得解析能力更不靠谱。

第二，使用习惯限制。尽管模型对于阅读上下文仍有限制，但模型能力的快速发展已经使得理解上下文的精准度逐渐提升。然而通用模型仍存在的另一个障碍，是用户的使用习惯。我们通常习惯将文本知识存入计算机文档或笔记管理工具中，用户希望的场景是自己所存储的内容能够原封不动的留在原处，然后接入模型能力对现有的知识库做检索分析。如果使用通用模型，则不得不每次都将内容打散再次上传，非常「麻烦」。而后又由于模型的上下文限制，每次能上传的内容不多，尤其法律从业者所希冀的法律法规库、案例库、实务指引库可能总量达到上百万乃至千万，当然是希望能够「一站式解决问题」。

那本地部署模型呢？也有两大限制问题：

其一，硬件限制。按自己现在的电脑配置，用 anythingllm 本地部署一个 deepseek-r1-7b 应该刚刚好，但即便是目前的 671b 满血版 r1，幻觉问题都严重到没法正常使用，推理过程惊艳但输出答案质量不高（据传明天发布 r2，非常期待），如果回退到 7b 版本，那还怎么用？如果要部署满血 671b 版本，听说苹果新出的八万块 m3 ultra 可以？但数据处理速度慢得感人。如果要堆显卡，据说需要 30~40 张 RTX 4090，价格感人。可问题是，有必要吗？

其二，向量转化能力限制。如前所说，模型识别、分析长文前，需要通过向量转化嵌入模型（通常是指 embedding 模型）将文本内容转化为计算机可识别的向量模型。即便是本地重金成功部署好了满血版 r1，或是使用第三方工具上传批量知识库，所面临的第一个问题就是如何将大量的知识库内容做向量转化从而满足模型精准输出的需求。所以即便部署好了满血版 r1，或是使用了第三方管理工具，仍要进一步选择本地部署较好的嵌入模型，模型的选择、转化质量等，同样又是导致知识库工具难以优质运转的限制问题。

因此，就目前阶段而言，我认为应该把自己从知识库 fomo 焦虑中跳脱出来，优先考虑一个更重要的问题：（1）对于既有知识，自己手上的垂直知识内容到底能有多少，是否已经到了自己无法消化、需要靠电子大脑帮助消化的程度？（2）对于未有知识，现有的工具是否已经不够用，到了需要花大价钱购买在线/本地知识库工具？—— 归结而言，抛开对工具的 fomo 焦虑，关注要点仍应当是：关注如何生产知识，而没到需要大规模整理知识的程度。

那具体应如何使用 LLM？chatgpt 诞生之初，微软也发布了自己的模型工具，命名为「Microsoft Copilot」，而后陆续出现了 github copilot、obsidian copilot 等。从「copilot」译作「副驾」的含义出发，我们可以将模型当成自己的「得力助手」，定位核心是「助手」。具体而言：

首先，如果我们的知识库不够，急需填充，在「快速研究」领域很多时候并不需要去全网检索文章，而是与模型耐心问答，对任一细节问题都可一步步扩充答案，让模型为你生成而非费力收集海量的知识库。如果担心模型答案因幻觉问题而胡编乱造，那一方面自己可以对答案做全文阅读，从专业知识或常识角度对答案作出修改。如果遇到自己不清楚的内容，可以将内容输入到多个模型进行交叉验证，例如可以使用 deepseek-r1 的联网能力做验证、使用 grok3 的 deep search 功能做验证或依赖 gpt-4.5 的庞大世界知识做验证等。对于专业垂直领域内容，我们可以求助于既有专业辅助工具，在我们行业可以是 alphalawyer、威科、meta.law 等，可以让模型对某一特定问题生成检索关键词或提示词，输入到工具中检索对应法律、案例作出验证。在这样的循环交叉验证帮助下，由模型去生成海量的知识内容，将极大减少我们「生成内容」的工作量，对验证后的结果也可放心使用。

然后，对于已生成的知识库内容，由于成本高昂且效果欠佳，我们在现阶段不需要非得依赖一个「大而全」的全能知识助手，仅需遵从模型的运行原理，针对特定、具体问题而使用通用模型获得答复。例如，在接到一个客户咨询，我们可以使用推理模型（如 deepseek-r1、gpt-o1、gemini-flash-thinking等），输入完整的案情描述和需求，让模型推理出关注要点，结果往往比自己考虑的范围还要广，以此作为灵感来源，再结合自己的专业调校，答复客户、庭前准备完全可用。甚至可以将案件材料发给模型（数据隐私保护是另一个话题，暂不讨论），让模型为你总结案情，再将总结结果发给模型推理，总之一切内容都可以让模型帮你生成。再例如，在确实需要输入海量知识库并希望从中获取灵感来源，那可以有目的地尝试市场上最新可用的 agent 工具，花点成本，上传海量知识库，通过与知识库对话获取灵感。此类工具的更新迭代非常快速，可以「以特定项目需求」而非「长期可用」为目标，挑选多个工具反复测试使用。

总而言之，以上方法始终遵循着一个原则：不论 LLM 模型与工具的发展有多快，对我们而言始终是一个个眼花缭乱的辅助工具。知识库的核心并不是工具，而是自己手中的数据知识本身。我们可以使用模型生产知识、累积知识，可以有目的地使用模型去分析知识，但决无必要产生模型知识库 fomo 焦虑。模型完全可以我们手中的「玩物」，对每一对话问题都可以多个模型同时使用，交叉验证和产出，并作好记录工作，这才可形成我们手上最珍贵的真正有用的知识库。