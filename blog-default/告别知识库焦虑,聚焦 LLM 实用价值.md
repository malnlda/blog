告别知识库焦虑，聚焦 LLM 实用价值

当前，大语言模型（LLM）和相关工具的竞争异常激烈，弃用 deepseek-r1、投奔 gpt-o1 才没多久，就体验到 grok-3 的 deep search 检索结果快速且精确，claude-sonnet-3.7 可以用「一杯瑞幸的钱」做出极高完成度且非常漂亮的网页和应用，gpt-4.5 具备更强大的世界知识、准确度和拟人度大幅提升，gemini-2.0 flash (image generation) 可以一句话修图、一句话生成数十张图片的分镜动作，gemini 也推出了 deep research，眼花缭乱，更不提 manus 等 agent 工具层出不穷搅动市场，以及明天（据传）就要发布 deepseek-r2 等等，极易激起用户对 ai 工具的 fomo 焦虑。在我看来，紧跟 LLM 模型和工具的发展进程固然重要，但不必频繁地转投「阵营」。工具毕竟只是工具，应当关注自己的使用场景，明确使用目标，进而按需选择。具体考虑过程有以下几个方面：

1. LLM 作为快速研究工具

以前，如果我们想要快速了解一本书，进入一个新领域，或者快速掌握某个主题的整体分析意见，通常会选择去豆瓣查阅书评，去知乎或公众号搜索相关的长篇文章。自从模型发展出 deep research 能力，以及类 deep research 工具涌现，在满足「快速研究」目的上，很大范围内已经不需要依赖传统的文章检索路径。例如，你可以向模型询问：「如果我想要：学习理解《古代法》这本书的整体内容 / 研究全世界范围内律师使用 LLM 的发展情况 / 研究人身商业保险在家庭财富传承和婚姻家事纠纷领域的相关问题，我应该如何设计提示词从而让模型生成高质量报告？」对模型生成的提示词结果，按需要做一些调整，比如「请你检索英语世界内容，并用中文输出 / 请你输出不少于两万中文字的结果」等，然后将调整好的提示词输入到 deep research 或类似工具中，等待生成结果。测试发现，这一结果的质量，足以实现「快速研究」的目标，能够从中提取学习和写作灵感，甚至稍作修改即可输出成专业文章。

2. LLM 作为知识库工具

通用模型的知识过于宽泛，无法满足我们本专业获取知识和团队协作的需求，因而需要搭建知识库，实现对既有知识内容的快速检索、总结、分析。这已成为全网关于 LLM 讨论最为热烈的话题，是最急切的需求，是使一大部分用户产生 fomo 焦虑最严重的话题。尤其在我们法律实务领域，在此话题下的 fomo 焦虑度更为甚之。律师日常工作需要解答客户法律咨询，但对于每个问题都不敢随意回答，进而需要做大量的法律研究、案例检索，消耗大量时间。LLM 的出现，deepseek-r1 的问世搅出一片天，但同行们很快发现通用模型的答案并不靠谱，会产生编造法条、案例的「幻觉」，故此更为急切地需要能够解决法律知识库的模型工具。于是，新橙推出了「alphagpt」，定价 ¥5000 /三年；熊猫推出「deepseek 大模型一体机」，价格不详；智合推出「deepseek 法律一体机」，价格 ¥500k……

在我看来，对于任何一件互联网上热烈炒作的事物，都需要打开我们脑子里的「防骗警报器」，审视自己是否有必要打开付款码淌入这片浑水。经过学习和了解，通用模型难以用于构建垂直领域的知识库，主要有两个原因：

第一，上下文长度的限制。在单轮对话中，为了维持对话记忆，模型在处理每次用户请求时，都需要重新读取包括历史对话在内的全部内容，这一过程会消耗计算单元——tokens。对话内容越多，单次请求消耗的 tokens 也随之增加。由于模型所能支持的最大上下文 tokens 数量存在限制，一旦对话总长度超出这一限制，模型便会遗忘早期的对话内容，导致回复质量下降。目前，deepseek-r1、gpt-4o 模型的上下文长度上限为 128k，约合 64k 中文字（api 接口为 32k 中文字），gemini-2.0-pro 善于处理长文，上限为 200k。从原理上，模型需要对输入文本进行「向量化」解析，即将自然语言转化为模型可识别的向量化数据。尽管 64k 中文字的上限看似较大，但不同模型在文本解析能力上存在差异，部分模型可能仅读取段落首句或重点部分，而非全文，这导致其解析效果可能不够稳定。

第二，使用习惯制约。尽管模型对于阅读上下文仍有限制，但模型能力的快速发展已经使得理解上下文的精准度逐渐提升，然而通用模型仍存在的另一个障碍——用户的使用习惯。我们通常习惯将文本知识存入计算机文档或笔记管理工具中，所希望的场景是存储内容能够原封不动的留在原处，并接入模型能力对现有的知识库做检索分析。如果使用通用模型，则不得不每次都将内容打散再次上传，非常「麻烦」。而后又由于模型的上下文限制，单次上传内容量受到限制，尤其对于法律从业者而言，其希望构建的法律法规库、案例库、实务指引库等知识库的数据总量可能达到百万甚至千万级别，所期望获得的当然是「一站式」的解决方案，而非多次循环工作。

那本地部署模型呢？也有两大限制问题：

其一，硬件配置限制。按我现在的电脑配置，用 anythingllm 本地部署一个 deepseek-r1-7b 应该勉强可行，但即便是目前的 671b 满血版 r1，「幻觉」问题都严重到没法正常使用，推理过程惊艳但输出答案质量不高，如果回退到 7b 版本，那对答复质量还能有什么期待？如果要部署满血 671b 版本，据说苹果新出的八万块 m3 ultra 可以，但数据处理速度慢得可怕；如果采用堆叠显卡方案，据说需要 30~40 张 RTX 4090 级别显卡方可实现，成本高昂。可问题是，这真的有必要吗？

其二，向量转化能力限制。如前所述，模型要识别和分析长文本，首先需要通过向量转化模型（通常指 embedding 模型）将文本内容转化为计算机可识别的向量数据。即便本地成功部署了完整版本的 r1，面临的第一个问题依然是如何将大量的知识库内容进行向量转化，以满足模型精确输出的需求。因此，即使成功部署了完整版本的 r1，或使用了第三方管理工具，仍然需要选择高效、优质的本地嵌入模型。这一模型的选择与转化质量等因素，依然是影响知识库工具优质运作的关键限制。

因此，目前阶段，我认为应当脱离知识库 fomo 焦虑，优先考虑以下两个问题：（1）对于既有知识，自己手上的垂直知识内容到底能有多少，是否已经到了自己无法消化、需要靠电子大脑帮助消化的程度？（2）对于未有知识，现有的工具是否已经不够用，到了需要花大价钱购买在线/本地知识库工具的时候？—— 归结而言，抛开对工具的 fomo 焦虑，关注如何生产知识，而非过度整理和管理知识库，才是当前的重点。

3. 应当如何使用 LLM？

Chatgpt 诞生之初，微软也发布了自己的模型工具，命名为「microsoft copilot」，而后陆续出现了 github copilot、obsidian copilot 等。借用「copilot」这一词，我们可以将模型视作自己的「得力助手」，主客分明，不能本末倒置。具体而言：

首先，如果我们的知识库不够，急需填充，在「快速研究」领域，很多时候无需全网检索文章，而是可以与模型耐心互动，通过不断提问，逐步补充细节，让模型生成完整的答案，进而整理成海量的知识库存。如果担心模型答案因「幻觉」问题而胡编乱造，则一方面可以由自己对答案做全文阅读，从专业知识或常识角度对答案作出修改；另一方面可以将内容输入到多个模型作交叉验证，例如可以使用 deepseek-r1 的联网能力、使用 grok-3 的 deep search 或依赖 gpt-4.5 的庞大世界知识做验证等。对于专业垂直领域内容，还可以求助于既有的专业辅助工具，在法律实务行业可以是 alphalawyer、威科、metalaw 等，可以让模型对某一特定问题生成检索关键词或提示词，进而将关键词或提示词输入到特定辅助工具中检索对应法律、案例作出验证。在这样的循环交叉验证帮助下，由模型去生成海量的知识内容，将极大减少我们「生成内容」的工作量，对验证后的结果也可放心使用。

然后，对于已生成的知识库内容，鉴于本地部署成本高昂且效果尚不理想，现阶段我们无需追求构建「大而全」的通用知识助手，更合理的策略是遵循模型的运行原理，针对特定、具体的问题，利用通用模型即可获得较为准确的解答。例如，在处理客户咨询时，我们可以借助推理能力较强的模型（如 deepseek-r1、gpt-4o、gemini-flash-thinking 等），输入完整的案情描述和客户需求，模型便能有效提炼出案件的关注要点，其分析结果往往较为全面，可作为案件处理的思路参考。在此基础上，结合专业知识进行调整和完善，即可用于回复客户、案件分析甚至庭前准备。甚至可以直接将案件材料脱密后提供给模型，让模型辅助案情摘要，再将摘要结果用于模型推理，解决「不知如何与模型对话」的问题。又如，在确有必要导入海量知识库以寻求灵感时，可以有针对性地尝试市场上最新的模型工具，花点成本，上传海量知识库，并通过与知识库对话获取灵感。此类工具的更新迭代非常快速，可以「以特定项目需求」而非「长期可用」为目标，挑选多个工具反复测试使用。

总而言之，以上方法始终遵循一个原则：无论 LLM 模型和工具如何快速发展，它们始终只是辅助工具。知识库的核心不在于工具，而在于我们手中的数据和知识。我们可以利用模型来生产和积累知识，也可以通过模型分析现有知识，但无需因工具的不断更新而产生 fomo 焦虑。在此基础上，我们可以理性等待市场出现更强大易用的知识库模型工具。知识数据始终掌握在手，届时再作更换和选择，便不存在错过机会之担忧。