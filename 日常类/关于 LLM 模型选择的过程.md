关于 LLM 模型选择的过程

0303

我大概是在 2023 年 3 月开始使用 chatgpt，模型类别从 gpt-3、3.5、4 一直发展到去年末的 4o。此前这些模型都是非推理模型，需要学习复杂的提示词技术，并通过提示词技术创建出足够好的 agents，才能在特定场景发挥作用，否则它们就仅仅是个聊天工具。但由于研究这些提示词技术太费时间，所以这个 plus 会员用着用着就荒废了。

Deepseek r1 发布后大概两周左右，确实有被 r1 呈现的推理过程和生成结果折服。当时认为 r1 已经能够满足日常工作和生活中对模型的大部分需求，于是退订 chatgpt plus 会员，专心使用 r1。

持续使用 r1 一个月后，我对模型的选择又发生了变化。通过浅层学习 r1 作为推理模型的基础原理，了解到市面上的推理模型已经不止一家，例如 gpt-o1、gemini 2.0 flash thinking，以及最新发布的 grok-3-reasoning、claude 3.7 sonnet 等。我从几个不同维度去体验不同模型生成的结果，包括简单问题询问、文稿润色、写作、上传知识库并要求模型从中抽取灵感等，涵盖了我日常工作与生活中对模型的主要需求。大致体验结果如下：

1. 日常问答：r1、o1 等推理模型回答速度实在太慢，使用 4o 能够非常快速地得到答复。
2. 文稿润色：r1 会出现严重的幻觉，「想太多」而把文稿改得面目全非。网传 grok-3 写稿最自然、最没有 ai 味，但我实际测试发现它的文风有些过于口水化，不适合我日常内容输出的需求。而 o1 改出来的文风能够在保持原有风格的基础上做出较好的润色，比较符合我的需求。这方面不得不提 gpt-4.5，目前最新也是无比昂贵的模型，在文稿修改方面效果真的很好，幻觉度很低，ai 味较少，将成为我在文稿润色方面的常驻模型。
3. 写稿：由于前面提到的幻觉问题，r1 在给定要求范围内写稿时经常严重超出范围，会「写飞」。gpt-o1、gemini 2.0 flash thinking 在写稿方面表现则确实不错，尤其是 o1 的文风非常稳。可以用 o1 写完初稿后，再拿去给 gpt-4.5 润色，效果挺好。
4. 灵感提取：分两个方面来说，一是不带预输入知识库的灵感提取，这一点 r1 和 o1 都做得不错。r1 的优势在于能呈现详细的思维链，可以直观看到它的幻觉和「想多」的过程，有助于拓展思维边界，但若论最终生成结果，还是 o1 更稳一些。二是带预输入知识库的灵感提取，这一点 r1 会由于幻觉问题而常常超出知识库范围去多想，而 o1 表现依然不错。

最后必须提一下 deep research，这是 chatgpt 至今为止最强大的模型。它以 gpt-o3 作为推理基础模型，号称通过网络爬取系统收集海量数据源，利用 o3 的强大推理能力，生成甚至高达数万字的高质量研究报告。但这个模型的定价是贵得离谱，chatgpt plus 用户每月仅有10次使用额度，pro 用户也不过每月 100 次。然而，对于 openai 这种「人无我有」的东西，实在无法责怪它的抢钱行为，真的很馋人。

回头想想，这一路折腾下来，从最初只想找个稳定趁手的工具，到现在越来越像在做业余模型测评了。而为了高效地使用这些工具，这样的探索与记录过程也确实是绕不开的，继续尝试吧。